{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvraj110/Sentiment-analysis-of-IMBD-rating/blob/main/IMDB_rating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data =pd.read_csv(\"imdb.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "7KWH_9sfinba"
      },
      "id": "7KWH_9sfinba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "802212d0"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn\n",
        "!pip install plotly\n",
        "!pip install nltk\n",
        "!pip install TextBlob\n",
        "!pip install spacy\n",
        "!pip install bs4\n",
        "!pip install sklearn\n",
        "!pip install wordcloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import numpy as np\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ],
      "id": "802212d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e58c732f"
      },
      "outputs": [],
      "source": [
        "#sentiment count\n",
        "data['airline_sentiment'].value_counts()"
      ],
      "id": "e58c732f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIAilpNGdd-y"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(data, x=\"airline_sentiment\")\n",
        "fig.update_traces(marker_color=\"turquoise\",marker_line_color='rgb(8,48,107)',\n",
        "                  marker_line_width=1.5)\n",
        "fig.update_layout(title_text='Airline Sentiment')\n",
        "fig.show()"
      ],
      "id": "NIAilpNGdd-y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d41421be"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# Create stopword list:\n",
        "stopwords = set(STOPWORDS)\n",
        "stopwords.update([\"br\", \"href\"])\n",
        "textt = \" \".join(text for text in data.text)\n",
        "wordcloud = WordCloud(stopwords=stopwords).generate(textt)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.savefig('wordcloud11.png')\n",
        "plt.show()"
      ],
      "id": "d41421be"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUk-xI6a4GAk"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\",  \"!\",'\"'))\n",
        "    return final\n",
        "data['text'] = data['text'].apply(remove_punctuation)\n",
        "data = data.dropna(subset=['text'])\n",
        "data['text'] = data['text'].apply(remove_punctuation)"
      ],
      "id": "MUk-xI6a4GAk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CilMDFAp4e7n"
      },
      "outputs": [],
      "source": [
        "#split the dataset  \n",
        "#train dataset\n",
        "train_reviews=data.text[:3800]\n",
        "train_sentiments=data.airline_sentiment[:3800]\n",
        "#test dataset\n",
        "test_reviews=data.text[3800:]\n",
        "test_sentiments=data.airline_sentiment[3800:]\n",
        "print(train_reviews.shape,train_sentiments.shape)\n",
        "print(test_reviews.shape,test_sentiments.shape)"
      ],
      "id": "CilMDFAp4e7n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPoKQDCl41N6"
      },
      "outputs": [],
      "source": [
        "#Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['text']=data['text'].apply(remove_special_characters)"
      ],
      "id": "hPoKQDCl41N6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdl1ONCe4-yv"
      },
      "outputs": [],
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['text']= data['text'].apply(simple_stemmer)"
      ],
      "id": "sdl1ONCe4-yv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldOlhkNx5HQg"
      },
      "outputs": [],
      "source": [
        "#Tokenization of text\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "tokenizer=ToktokTokenizer()\n",
        "#Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ],
      "id": "ldOlhkNx5HQg"
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['text']=data['text'].apply(denoise_text)"
      ],
      "metadata": {
        "id": "fwIdzmyrGC5p"
      },
      "id": "fwIdzmyrGC5p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['text']= data['text'].apply(remove_special_characters)"
      ],
      "metadata": {
        "id": "7fMzBA5qHF0b"
      },
      "id": "7fMzBA5qHF0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jm35MnYvlQu"
      },
      "outputs": [],
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "#Apply function on review column\n",
        "data['text']=data['text'].apply(simple_stemmer)"
      ],
      "id": "8jm35MnYvlQu"
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "data['text']=data['text'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "azYQyzioHmhA"
      },
      "id": "azYQyzioHmhA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNJ1DWu_vlQo"
      },
      "outputs": [],
      "source": [
        "#normalized train reviews\n",
        "norm_train_reviews=data.text[:3800]\n",
        "norm_train_reviews[0]\n",
        "#convert dataframe to string\n",
        "#norm_train_string=norm_train_reviews.to_string()\n",
        "#Spelling correction using Textblob\n",
        "#norm_train_spelling=TextBlob(norm_train_string)\n",
        "#norm_train_spelling.correct()\n",
        "#Tokenization using Textblob\n",
        "#norm_train_words=norm_train_spelling.words\n",
        "#norm_train_words"
      ],
      "id": "dNJ1DWu_vlQo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax4QzgHMvlQs"
      },
      "outputs": [],
      "source": [
        "#Normalized test reviews\n",
        "norm_test_reviews=data.text[3800:]\n",
        "norm_test_reviews[3900]\n",
        "##convert dataframe to string\n",
        "#norm_test_string=norm_test_reviews.to_string()\n",
        "#spelling correction using Textblob\n",
        "#norm_test_spelling=TextBlob(norm_test_string)\n",
        "#print(norm_test_spelling.correct())\n",
        "#Tokenization using Textblob\n",
        "#norm_test_words=norm_test_spelling.words\n",
        "#norm_test_words"
      ],
      "id": "ax4QzgHMvlQs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGcMzWAFvlQv"
      },
      "outputs": [],
      "source": [
        "#Count vectorizer for bag of words\n",
        "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
        "#transformed train reviews\n",
        "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
        "#transformed test reviews\n",
        "cv_test_reviews=cv.transform(norm_test_reviews)\n",
        "\n",
        "print('BOW_cv_train:',cv_train_reviews.shape)\n",
        "print('BOW_cv_test:',cv_test_reviews.shape)"
      ],
      "id": "OGcMzWAFvlQv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59q2qSb7vlQx"
      },
      "outputs": [],
      "source": [
        "#Tfidf vectorizer\n",
        "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
        "#transformed train reviews\n",
        "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
        "#transformed test reviews\n",
        "tv_test_reviews=tv.transform(norm_test_reviews)\n",
        "print('Tfidf_train:',tv_train_reviews.shape)\n",
        "print('Tfidf_test:',tv_test_reviews.shape)"
      ],
      "id": "59q2qSb7vlQx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj40xiiVvlQz"
      },
      "outputs": [],
      "source": [
        "#labeling the sentient data\n",
        "lb=LabelBinarizer()\n",
        "#transformed sentiment data\n",
        "sentiment_data=lb.fit_transform(data['airline_sentiment'])\n",
        "print(sentiment_data.shape)"
      ],
      "id": "qj40xiiVvlQz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c15e6354"
      },
      "outputs": [],
      "source": [
        "#Spliting the sentiment data\n",
        "train_sentiments=sentiment_data[:3800]\n",
        "test_sentiments=sentiment_data[3800:]\n",
        "print(train_sentiments)\n",
        "print(test_sentiments)"
      ],
      "id": "c15e6354"
    },
    {
      "cell_type": "code",
      "source": [
        "data['airline_sentiment'] = data['airline_sentiment'].replace({'negative' : -1})\n",
        "data['airline_sentiment'] = data['airline_sentiment'].replace({'positive': 1})\n",
        "data['airline_sentiment'] = data['airline_sentiment'].replace({'neutral': 0})\n",
        "fig = px.histogram(data, x=\"airline_sentiment\")\n",
        "fig.update_traces(marker_color=\"indianred\",marker_line_color='rgb(8,48,107)',\n",
        "                  marker_line_width=1.5)\n",
        "fig.update_layout(title_text='Airline Sentiment')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2ZL64QUylvDl"
      },
      "id": "2ZL64QUylvDl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfNew = data[['text','airline_sentiment']]\n",
        "dfNew.head()"
      ],
      "metadata": {
        "id": "0afi1Ce1XiCU"
      },
      "id": "0afi1Ce1XiCU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random split train and test data\n",
        "index = data.index\n",
        "data['random_number'] = np.random.randn(len(index))\n",
        "train = data[data['random_number'] <= 0.8]\n",
        "test = data[data['random_number'] > 0.8]"
      ],
      "metadata": {
        "id": "M3klcUYbm_Dw"
      },
      "id": "M3klcUYbm_Dw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count vectorizer:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
        "train_matrix = vectorizer.fit_transform(train['text'])\n",
        "test_matrix = vectorizer.transform(test['text'])"
      ],
      "metadata": {
        "id": "duLslJoEnLo-"
      },
      "id": "duLslJoEnLo-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38dbfdb2"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()"
      ],
      "id": "38dbfdb2"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_matrix\n",
        "X_test = test_matrix\n",
        "y_train = train['airline_sentiment']\n",
        "y_test = test['airline_sentiment']"
      ],
      "metadata": {
        "id": "2PgdrxhBo6L6"
      },
      "id": "2PgdrxhBo6L6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Lut_kxgrpZ5K"
      },
      "id": "Lut_kxgrpZ5K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr.predict(X_test)"
      ],
      "metadata": {
        "id": "D6Q_7rkqpnF6"
      },
      "id": "D6Q_7rkqpnF6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find accuracy, precision, recall:\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "new = np.asarray(y_test)\n",
        "confusion_matrix(predictions,y_test)"
      ],
      "metadata": {
        "id": "UD7DsCbwpq_6"
      },
      "id": "UD7DsCbwpq_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions,y_test))"
      ],
      "metadata": {
        "id": "urpAdvbOpuVP"
      },
      "id": "urpAdvbOpuVP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}